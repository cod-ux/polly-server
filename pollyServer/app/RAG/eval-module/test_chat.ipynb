{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/suryaganesan/Documents/GitHub/polly-server/pollyServer/app/RAG/eval-module/../chroma'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import toml\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from phoenix.otel import register\n",
    "\n",
    "from ragas.metrics import (\n",
    "    FactualCorrectness,\n",
    "    Faithfulness,\n",
    "    SemanticSimilarity,\n",
    "    LLMContextRecall,\n",
    ")\n",
    "from ragas import evaluate\n",
    "from ragas import EvaluationDataset\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "secrets_path = os.path.join(BASE_DIR, \"..\", \"..\", \"config\", \"secrets.toml\")\n",
    "docs_folder = os.path.join(BASE_DIR, \"docs\")\n",
    "prompt_folder = os.path.join(BASE_DIR, \"prompts\")\n",
    "\n",
    "queries_path = os.path.join(BASE_DIR, \"..\", \"eval-ds\", \"Queries.xlsx\")\n",
    "output_folder = os.path.join(BASE_DIR, \"..\", \"eval-ds\")\n",
    "\n",
    "API_KEY = toml.load(secrets_path)[\"OPENAI_API_KEY\"]\n",
    "GROQ_KEY = toml.load(secrets_path)[\"GROQ_KEY\"]\n",
    "\n",
    "embedding_model = \"text-embedding-3-large\"\n",
    "embeddings = OpenAIEmbeddings(model=embedding_model, api_key=API_KEY)\n",
    "\n",
    "client = OpenAI(api_key=GROQ_KEY, base_url=\"https://api.groq.com/openai/v1\")\n",
    "\n",
    "chroma_dir = os.path.join(BASE_DIR, \"..\", \"chroma\")\n",
    "chroma_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare vector store\n",
    "vector_store = Chroma(\n",
    "    persist_directory=chroma_dir,\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"polly-rag\",\n",
    ")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
    "\n",
    "# Prepare LLM Judge\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "\n",
    "\n",
    "def query_db(query: str):\n",
    "    results = vector_store.similarity_search(query=query, k=3)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Prepare chat function\n",
    "def generate_response(question):\n",
    "    # Query VectorDB\n",
    "    source = query_db(question)\n",
    "    context = [page.page_content for page in source]\n",
    "    string_context = \"\\n\".join(context)\n",
    "\n",
    "    with open(os.path.join(prompt_folder, \"system.md\"), \"r\", encoding=\"utf-8\") as file:\n",
    "        system_prompt = file.read()\n",
    "\n",
    "    with open(os.path.join(prompt_folder, \"user.md\"), \"r\", encoding=\"utf-8\") as file:\n",
    "        user_prompt = file.read()\n",
    "\n",
    "    response = (\n",
    "        client.chat.completions.create(\n",
    "            model=\"llama-3.2-11b-vision-preview\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt.format(context=string_context),\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": user_prompt.format(question=question)},\n",
    "            ],\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.content\n",
    "    )\n",
    "\n",
    "    return response, context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'figure_title': 'Figure 1: To what extent do you agree with the statement that “the civil service takes ', 'page_no': 15, 'source': '/Users/suryaganesan/Documents/GitHub/polly-server/pollyServer/app/RAG/docs/Making-the-grade.pdf'}, page_content='Source document: Making-the-grade.pdf \\nPage no: 15 \\nFigure 1: To what extent do you agree with the statement that “the civil service takes \\n\\nFigure Description: \\nCertainly! Here\\'s a detailed description of the data presented in the figures:\\n\\n### Figure 1: Agreement with the Statement \"The civil service takes talent and performance management seriously\"\\n\\nThis figure is a bar graph representing survey respondents\\' levels of agreement with the statement.\\n\\n- **Strongly agree**: 3%\\n- **Somewhat agree**: 26%\\n- **Neither agree nor disagree**: 13%\\n- **Somewhat disagree**: 30%\\n- **Strongly disagree**: 27%\\n- **Don\\'t know**: 1%\\n\\n### Figure 2: Agreement with the Statement \"I am aware of disciplinary issues where action should have been taken but has not\"\\n\\nThis figure is also a bar graph with the following responses:\\n\\n- **Strongly agree**: 34%\\n- **Somewhat agree**: 28%\\n- **Neither agree nor disagree**: 13%\\n- **Somewhat disagree**: 10%\\n- **Strongly disagree**: 7%\\n- **Don\\'t know**: 8%\\n\\n### Insights:\\n\\n- In Figure 1, only a combined 29% (3% strongly agree, 26% somewhat agree) of respondents feel the civil service takes talent and performance management seriously, while a combined 57% feel otherwise (30% somewhat disagree, 27% strongly disagree).\\n\\n- Figure 2 reveals that a significant 62% (34% strongly agree, 28% somewhat agree) of respondents are aware of disciplinary issues that were not addressed, suggesting concerns about accountability.\\n\\n### Additional Context:\\n\\nThe text below the figures suggests these perceptions may be influenced by the decentralization of workforce responsibility across government departments, which allows for significant variation in the implementation of plans.'),\n",
       " Document(metadata={'figure_title': 'Figure 17 : To what extent do you agree with the statement that “managers are ', 'page_no': 54, 'source': '/Users/suryaganesan/Documents/GitHub/polly-server/pollyServer/app/RAG/docs/Making-the-grade.pdf'}, page_content='Source document: Making-the-grade.pdf \\nPage no: 54 \\nFigure 17 : To what extent do you agree with the statement that “managers are \\n\\nFigure Description: \\nThe figure illustrates survey responses regarding the statement: \"Managers are incentivised to move poor performers to another role or department, rather than manage them out of the civil service.\"\\n\\n### Survey Response Breakdown\\n- **Strongly Agree**: 31%\\n- **Somewhat Agree**: 35%\\n- **Neither Agree nor Disagree**: 14%\\n- **Somewhat Disagree**: 7%\\n- **Strongly Disagree**: 8%\\n- **Don’t Know**: 5%\\n\\n### Key Insights\\n- A significant majority (66%) either strongly or somewhat agree with the statement, indicating a prevalent belief that managers prefer reallocating poor performers rather than addressing their performance issues directly.\\n- A smaller proportion (15%) express disagreement to some degree.\\n- A minority of respondents either refrain from taking a clear stance or lack sufficient information to form an opinion (14% neither agree nor disagree, 5% don’t know).\\n\\n### Additional Information\\n- The text notes a worrisome trend among Grade 6 and SCS respondents, with 54% and 46% strongly agreeing, respectively.\\n- Nearly 40% of line managers also strongly agree with the statement.\\n\\nThis data underscores concerns about managerial strategies regarding poor performance within the civil service and suggests a possible need for reviewing such practices.'),\n",
       " Document(metadata={'page': 46, 'source': '/Users/suryaganesan/Documents/GitHub/polly-server/pollyServer/app/RAG/docs/Making-the-grade.pdf'}, page_content='Source name: Making-the-grade.pdf\\n\\n  Making the grade  \\n47 \\n  \\n \\nOf those respondents to the Reform /CSW survey who reported being line managers, two \\nthirds disagreed or strongly disagreed with the statement : “I feel supported through my training \\nto manage poor performance and disciplinary matters”.  Less than a quarter reported feeling \\nsupported.  \\n \\nFigure 13: As a line manager, to what extent do you agree with the statement that “I feel \\nsupported through my training to manage poor performance and disciplinary matters” ? \\n \\n \\n4%19%\\n15%41%\\n21%\\n0%10%20%30%40%50%\\nStrongly agree Somewhat agree Neither agree nor\\ndisagreeSomewhat disagree Strongly disagree\"I feel supported through my training to manage poor \\nperformance and disciplinary matters\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"What percentage of respondents strongly or somewhat agreed with the statement 'I am aware of disciplinary issues where action should have been taken but has not'?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation\n",
    "# Prepare dataset - List of dicts [{\"reference\": \"\", \"query\": \"\", \"response\": \"\"}...]\n",
    "# Context precision, Context recall, Response Relevancy, Faithfullness\n",
    "\n",
    "# Iterate through queries - make dataframe with reference, query, response\n",
    "\n",
    "\n",
    "def build_eval_ds(queries_df, evals_df):\n",
    "    print(\"Building evaluation dataset...\")\n",
    "    questions = []\n",
    "    answers = []\n",
    "    contexts = []\n",
    "    ground_truth = []\n",
    "    for index, row in queries_df.iterrows():\n",
    "        length = len(queries_df)\n",
    "        print(f\"Working on question: {index+1}/{length}\")\n",
    "        questions.append(row[\"Queries\"])\n",
    "        ground_truth.append(row[\"Ground truth\"])\n",
    "        answer, context = generate_response(row[\"Queries\"])\n",
    "        answers.append(answer)\n",
    "        contexts.append(context)\n",
    "\n",
    "    evals_df[\"user_input\"] = questions\n",
    "    evals_df[\"response\"] = answers\n",
    "    evals_df[\"retrieved_contexts\"] = contexts\n",
    "    evals_df[\"reference\"] = [str(truth) for truth in ground_truth]\n",
    "\n",
    "    evals_dataset = EvaluationDataset.from_pandas(evals_df)\n",
    "    return evals_dataset\n",
    "\n",
    "\n",
    "def run_eval(df, llm=evaluator_llm, emd=evaluator_embeddings):\n",
    "    print(\"Running evaluation...\")\n",
    "    metrics = [\n",
    "        LLMContextRecall(llm=llm),\n",
    "        FactualCorrectness(llm=llm),\n",
    "        Faithfulness(llm=llm),\n",
    "        SemanticSimilarity(embeddings=evaluator_embeddings),\n",
    "    ]\n",
    "    results = evaluate(dataset=df, metrics=metrics).to_pandas()\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building evaluation dataset...\n",
      "Working on question: 1/12\n",
      "Working on question: 2/12\n",
      "Working on question: 3/12\n",
      "Working on question: 4/12\n",
      "Working on question: 5/12\n",
      "Working on question: 6/12\n",
      "Working on question: 7/12\n",
      "Working on question: 8/12\n",
      "Working on question: 9/12\n",
      "Working on question: 10/12\n",
      "Working on question: 11/12\n",
      "Working on question: 12/12\n",
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  27%|██▋       | 13/48 [00:06<00:19,  1.75it/s]Exception raised in Job[17]: TypeError(ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe'')\n",
      "Evaluating:  35%|███▌      | 17/48 [00:09<00:22,  1.38it/s]Exception raised in Job[9]: TypeError(ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe'')\n",
      "Evaluating:  71%|███████   | 34/48 [00:15<00:07,  1.96it/s]Exception raised in Job[37]: TypeError(ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe'')\n",
      "Evaluating: 100%|██████████| 48/48 [00:44<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename exists...\n",
      "Filename is valid...\n",
      "Saved file...\n",
      "Save 2411-llama3.211b-fixedimgs.xlsx successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "eval_df = pd.DataFrame()\n",
    "query_df = pd.read_excel(queries_path)\n",
    "\n",
    "# Initating test\n",
    "\n",
    "response_ds = build_eval_ds(queries_df=query_df, evals_df=eval_df)\n",
    "eval_results = run_eval(response_ds)\n",
    "\n",
    "filename = input(\"Save table as: \")\n",
    "\n",
    "Saved = False\n",
    "while not Saved:\n",
    "    if filename:\n",
    "        print(\"Filename exists...\")\n",
    "        if not os.path.exists(\n",
    "            os.path.join(output_folder, \"output\", f\"{filename}.xlsx\")\n",
    "        ):\n",
    "            print(\"Filename is valid...\")\n",
    "            eval_results.to_excel(\n",
    "                os.path.join(output_folder, \"output\", f\"{filename}.xlsx\"),\n",
    "                index=False,\n",
    "            )\n",
    "            print(\"Saved file...\")\n",
    "            print(f\"Save {filename}.xlsx successfully\")\n",
    "            Saved = True\n",
    "\n",
    "        else:\n",
    "            print(\"File already exists\")\n",
    "\n",
    "    else:\n",
    "        print(\"Please enter a valid name to save the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>factual_correctness</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of the \"General Power of C...</td>\n",
       "      <td>The \"General Power of Competence\" is a law tha...</td>\n",
       "      <td>The \"General Power of Competence,\" as outlined...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.971718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the causes for concern in England's l...</td>\n",
       "      <td>The causes for concern in England's local gove...</td>\n",
       "      <td>The main concerns with England's local governm...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What percentage of line managers somewhat disa...</td>\n",
       "      <td>According to the data, 41% of line managers so...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.771277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the Department of Health and Social C...</td>\n",
       "      <td>The Department of Health and Social Care's res...</td>\n",
       "      <td>The response to the FOI request is not clear o...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What percentage of line managers strongly disa...</td>\n",
       "      <td>According to the results, 21% of line managers...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.797666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What contributed to the Windrush scandal?</td>\n",
       "      <td>According to the provided text, the operationa...</td>\n",
       "      <td>“Operational and organisational failing” at th...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the delivery and administrative power...</td>\n",
       "      <td>In England, local government is divided into s...</td>\n",
       "      <td>In England, local governments possess specific...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.936730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the primary focus of Reform's new prog...</td>\n",
       "      <td>The primary focus of Reform's new programme, \"...</td>\n",
       "      <td>The primary focus of Reform's new programme, \"...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What percentage of respondents strongly or som...</td>\n",
       "      <td>Respondents who strongly or somewhat agreed wi...</td>\n",
       "      <td>62 per cent</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What was the rank of the UK in terms of measle...</td>\n",
       "      <td>The UK's measles immunisation coverage ranked ...</td>\n",
       "      <td>31st</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does Reform define AI?</td>\n",
       "      <td>Reform defines AI as \"Theories and techniques ...</td>\n",
       "      <td>Theories and techniques developed to allow com...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Is there a risk of a 'race to the bottom' in d...</td>\n",
       "      <td>There is a concern that local authorities migh...</td>\n",
       "      <td>There is a concern that increased decentralisa...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   What is the purpose of the \"General Power of C...   \n",
       "1   What are the causes for concern in England's l...   \n",
       "2   What percentage of line managers somewhat disa...   \n",
       "3   How does the Department of Health and Social C...   \n",
       "4   What percentage of line managers strongly disa...   \n",
       "5           What contributed to the Windrush scandal?   \n",
       "6   What are the delivery and administrative power...   \n",
       "7   What is the primary focus of Reform's new prog...   \n",
       "8   What percentage of respondents strongly or som...   \n",
       "9   What was the rank of the UK in terms of measle...   \n",
       "10                         How does Reform define AI?   \n",
       "11  Is there a risk of a 'race to the bottom' in d...   \n",
       "\n",
       "                                             response  \\\n",
       "0   The \"General Power of Competence\" is a law tha...   \n",
       "1   The causes for concern in England's local gove...   \n",
       "2   According to the data, 41% of line managers so...   \n",
       "3   The Department of Health and Social Care's res...   \n",
       "4   According to the results, 21% of line managers...   \n",
       "5   According to the provided text, the operationa...   \n",
       "6   In England, local government is divided into s...   \n",
       "7   The primary focus of Reform's new programme, \"...   \n",
       "8   Respondents who strongly or somewhat agreed wi...   \n",
       "9   The UK's measles immunisation coverage ranked ...   \n",
       "10  Reform defines AI as \"Theories and techniques ...   \n",
       "11  There is a concern that local authorities migh...   \n",
       "\n",
       "                                            reference  context_recall  \\\n",
       "0   The \"General Power of Competence,\" as outlined...            0.75   \n",
       "1   The main concerns with England's local governm...            1.00   \n",
       "2                                                0.41            1.00   \n",
       "3   The response to the FOI request is not clear o...            1.00   \n",
       "4                                                0.21            1.00   \n",
       "5   “Operational and organisational failing” at th...            1.00   \n",
       "6   In England, local governments possess specific...            0.80   \n",
       "7   The primary focus of Reform's new programme, \"...            1.00   \n",
       "8                                         62 per cent            1.00   \n",
       "9                                                31st            1.00   \n",
       "10  Theories and techniques developed to allow com...            1.00   \n",
       "11  There is a concern that increased decentralisa...            1.00   \n",
       "\n",
       "    factual_correctness  faithfulness  semantic_similarity  \n",
       "0                  0.73      0.500000             0.971718  \n",
       "1                  0.45      1.000000             0.958417  \n",
       "2                   NaN      0.857143             0.771277  \n",
       "3                  0.89      1.000000             0.908341  \n",
       "4                   NaN      1.000000             0.797666  \n",
       "5                  0.00      0.400000             0.898321  \n",
       "6                  0.41      0.750000             0.936730  \n",
       "7                  0.74      1.000000             0.991734  \n",
       "8                  0.00      1.000000             0.819587  \n",
       "9                   NaN      1.000000             0.769989  \n",
       "10                 0.29      1.000000             0.870022  \n",
       "11                 0.42      1.000000             0.949097  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results[[\"user_input\", \"response\", \"reference\", \"context_recall\", \"factual_correctness\", \"faithfulness\", \"semantic_similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Context Recall: 0.96\n",
      "Factual Correctness: 0.33\n",
      "Faithfulness: 0.88\n",
      "Semantic Similarity: 0.89\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary:\")\n",
    "round_up = 2\n",
    "\n",
    "context_recall = eval_results[\"context_recall\"].fillna(0).values\n",
    "cr_avg = sum(context_recall)/len(context_recall)\n",
    "print(f\"Context Recall: {round(cr_avg, round_up)}\")\n",
    "\n",
    "factual_correctness = eval_results[\"factual_correctness\"].fillna(0).values\n",
    "fc_avg = sum(factual_correctness)/len(factual_correctness)\n",
    "print(f\"Factual Correctness: {round(fc_avg, round_up)}\")\n",
    "\n",
    "faithfulness = eval_results[\"faithfulness\"].fillna(0).values\n",
    "ff_avg = sum(faithfulness)/len(faithfulness)\n",
    "print(f\"Faithfulness: {round(ff_avg, round_up)}\")\n",
    "\n",
    "semantic_similarity = eval_results[\"semantic_similarity\"].fillna(0).values\n",
    "ss_avg = sum(semantic_similarity)/len(semantic_similarity)\n",
    "print(f\"Semantic Similarity: {round(ss_avg, round_up)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
